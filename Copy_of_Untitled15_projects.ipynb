{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqcE2y9Zr3RFxOUs9jNt7Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/f2024065214-ops/projects-for-ML-supervised-learning-part1-/blob/main/Copy_of_Untitled15_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "df = housing.frame\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "lr_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LinearRegression())\n",
        "])\n",
        "\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "y_pred = lr_pipeline.predict(X_test)\n",
        "\n",
        "print(\"First 5 predictions:\", y_pred[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeSYAQYndlOm",
        "outputId": "ba5f6f6b-9165-4977-d11d-92da3b4223b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (20640, 8)\n",
            "y shape: (20640,)\n",
            "First 5 predictions: [0.71912284 1.76401657 2.70965883 2.83892593 2.60465725]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "df = housing.frame\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"poly\", PolynomialFeatures(include_bias=False)),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LinearRegression())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"poly__degree\": [1, 2, 3]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"r2\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-val R²:\", grid.best_score_)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "from sklearn.metrics import r2_score\n",
        "print(\"Test R²:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnYyhe8Hfp4L",
        "outputId": "79bc42fe-4639-406d-8df3-fa7c2c17fa49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'poly__degree': 1}\n",
            "Best cross-val R²: 0.6110921251096776\n",
            "Test R²: 0.575787706032451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "df = housing.frame\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "lin_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LinearRegression())\n",
        "])\n",
        "\n",
        "lin_pipeline.fit(X_train, y_train)\n",
        "y_pred_lin = lin_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Linear Regression Performance:\")\n",
        "print(\"R²:\", r2_score(y_test, y_pred_lin))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_lin))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [10, 20, None],\n",
        "    \"min_samples_split\": [2, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    rf,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"r2\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best RandomForest Params:\", grid.best_params_)\n",
        "print(\"Best Cross-val R²:\", grid.best_score_)\n",
        "\n",
        "y_pred_rf = grid.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Performance:\")\n",
        "print(\"Test R²:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilY9H3mOjNV9",
        "outputId": "791c1a3e-528e-42e0-f6d1-f124187b2f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Performance:\n",
            "R²: 0.575787706032451\n",
            "MSE: 0.5558915986952442\n",
            "--------------------------------------------------\n",
            "Best RandomForest Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Cross-val R²: 0.8013884636036114\n",
            "Random Forest Performance:\n",
            "Test R²: 0.8061857564039718\n",
            "Test MSE: 0.2539759249192041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df= pd.read_csv(/content/maham-farooq)\n",
        "df.head()\n",
        "\n",
        "x= df.drop(columns= ['selling_price'],axis=1)\n",
        "y= df['selling_price']\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42\n",
        ")\n",
        "numeric_features = x.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "categorical_features = x.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "ni= Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"scaler\",ni,numeric_features),\n",
        "        (\"cat\",categorical_transformer,categorical_features)\n",
        "\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessor\",preprocessor),\n",
        "    (\"model\", RandomForestRegressor(random_state=42))\n",
        "])\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred_lin = pipeline.predict(X_test)\n",
        "print(y_pred_lin)\n",
        "param_grid = {\n",
        "    \"model__n_estimators\": [100,200],\n",
        "    \"model__max_depth\": [10,20,None],\n",
        "    \"model__min_samples_split\": [2,5]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"r2\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best RandomForest Params:\", grid.best_params_)\n",
        "print(\"Best Cross-val R²:\", grid.best_score_)\n",
        "y_pred_rf = grid.predict(X_test)\n",
        "print(\"random Regression Performance:\")\n",
        "print(\"R²:\", r2_score(y_test, y_pred_lin))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_lin))\n",
        "print(\"-\" * 50)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_pred_rf, alpha=0.6, color=\"blue\")\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel(\"Actual Selling Price\")\n",
        "plt.ylabel(\"Predicted Selling Price\")\n",
        "plt.title(\"Actual vs Predicted - Random Forest\")\n",
        "plt.show()\n",
        "\n",
        "residuals = y_test - y_pred_rf\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(y_pred_rf, residuals, alpha=0.6, color=\"green\")\n",
        "plt.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
        "plt.xlabel(\"Predicted Selling Price\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(x['km_driven'], y, alpha=0.6, color=\"green\")\n",
        "plt.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
        "plt.xlabel(\"Predicted Selling Price\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "v2OGObz-MMV9",
        "outputId": "f7f6c962-cdf8-48a1-e2cc-1c4a5b1845b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1485293267.py, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1485293267.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    df= pd.read_csv(/content/maham-farooq)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "data = load_breast_cancer(as_frame= True)\n",
        "df= data.frame\n",
        "X = df.drop(columns=['target'])\n",
        "y = data.target\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Classes:\", np.unique(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "log_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=5000, random_state=42))\n",
        "])\n",
        "\n",
        "log_param_grid = {\n",
        "    \"clf__C\": [0.1, 1, 10],\n",
        "    \"clf__penalty\": [\"l2\"],\n",
        "    \"clf__solver\": [\"lbfgs\", \"saga\"]\n",
        "}\n",
        "\n",
        "log_grid = GridSearchCV(log_pipeline, log_param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "log_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Logistic Regression Params:\", log_grid.best_params_)\n",
        "print(\"Best CV Accuracy:\", log_grid.best_score_)\n",
        "\n",
        "y_pred_log = log_grid.predict(X_test)\n",
        "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", SVC(probability=True,random_state=42))\n",
        "])\n",
        "\n",
        "svm_param_grid = {\n",
        "    \"clf__C\": [0.1, 1, 10],\n",
        "    \"clf__kernel\": [\"linear\", \"rbf\"],\n",
        "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
        "}\n",
        "\n",
        "svm_grid = GridSearchCV(svm_pipeline, svm_param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "svm_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest SVM Params:\", svm_grid.best_params_)\n",
        "print(\"Best CV Accuracy:\", svm_grid.best_score_)\n",
        "\n",
        "y_pred_svm = svm_grid.predict(X_test)\n",
        "print(\"SVM Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "\n",
        "rf_pipeline = Pipeline([\n",
        "    (\"clf\", RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "rf_param_grid = {\n",
        "    \"clf__n_estimators\": [100, 200],\n",
        "    \"clf__max_depth\": [10, 20, None],\n",
        "    \"clf__min_samples_split\": [2, 5]\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(rf_pipeline, rf_param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest RandomForest Params:\", rf_grid.best_params_)\n",
        "print(\"Best CV Accuracy:\", rf_grid.best_score_)\n",
        "\n",
        "y_pred_rf = rf_grid.predict(X_test)\n",
        "print(\"Random Forest Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "\n",
        "results = {\n",
        "    \"Logistic Regression\": accuracy_score(y_test, y_pred_log),\n",
        "    \"SVM\": accuracy_score(y_test, y_pred_svm),\n",
        "    \"Random Forest\": accuracy_score(y_test, y_pred_rf)\n",
        "}\n",
        "\n",
        "print(\"\\nModel Comparison on Test Set:\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc: 4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Confusion Matrix for best model\n",
        "# -----------------------------\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"\\nBest model is: {best_model}\")\n",
        "\n",
        "if best_model == \"Logistic Regression\":\n",
        "    y_best = y_pred_log\n",
        "elif best_model == \"SVM\":\n",
        "    y_best = y_pred_svm\n",
        "else:\n",
        "    y_best = y_pred_rf\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_best))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_best))\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(results.keys(), results.values(), color=[\"skyblue\",\"orange\",\"green\"])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Comparison on Breast Cancer Dataset\")\n",
        "plt.show()\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Actual\": y_test[:20],\n",
        "    \"Predicted\": y_best[:20]\n",
        "})\n",
        "print(\"\\nFirst 20 Predictions (Actual vs Predicted):\\n\")\n",
        "print(comparison_df)\n",
        "\n",
        "manual_data = np.array([[\n",
        "    14.2, 20.5, 90.1, 600.2, 0.1,\n",
        "    0.15, 0.2, 0.25, 0.1, 0.2,\n",
        "    0.8, 1.5, 5.0, 50.0, 0.005,\n",
        "    0.03, 0.04, 0.02, 0.02, 0.006,\n",
        "    16.0, 25.0, 105.0, 800.0, 0.12,\n",
        "    0.20, 0.25, 0.3, 0.15, 0.07\n",
        "]])\n",
        "\n",
        "# Predict using the best model\n",
        "if best_model == \"Logistic Regression\":\n",
        "    model = log_grid.best_estimator_\n",
        "elif best_model == \"SVM\":\n",
        "    model = svm_grid.best_estimator_\n",
        "else:\n",
        "    model = rf_grid.best_estimator_\n",
        "\n",
        "pred = model.predict(manual_data)[0]\n",
        "\n",
        "if pred == 0:\n",
        "    print(\"Prediction: Malignant (Cancerous Tumor)\")\n",
        "else:\n",
        "    print(\"Prediction: Benign (Non-Cancerous Tumor)\")\n",
        "\n",
        "if hasattr(model, \"predict_proba\"):\n",
        "    prob = model.predict_proba(manual_data)[0]\n",
        "    print(\"Confidence:\", np.max(prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z3k2cEsxOYKe",
        "outputId": "5c4365bb-b53b-4de9-9fba-e530cf7a4c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (569, 30)\n",
            "Classes: [0 1]\n",
            "\n",
            "Best Logistic Regression Params: {'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n",
            "Best CV Accuracy: 0.9802197802197803\n",
            "Logistic Regression Test Accuracy: 0.9736842105263158\n",
            "\n",
            "Best SVM Params: {'clf__C': 0.1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
            "Best CV Accuracy: 0.9780219780219781\n",
            "SVM Test Accuracy: 0.9824561403508771\n",
            "\n",
            "Best RandomForest Params: {'clf__max_depth': 10, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\n",
            "Best CV Accuracy: 0.9604395604395606\n",
            "Random Forest Test Accuracy: 0.956140350877193\n",
            "\n",
            "Model Comparison on Test Set:\n",
            "Logistic Regression:  0.973684\n",
            "SVM:  0.982456\n",
            "Random Forest:  0.956140\n",
            "\n",
            "Best model is: SVM\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        42\n",
            "           1       0.99      0.99      0.99        72\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[41  1]\n",
            " [ 1 71]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 20 Predictions (Actual vs Predicted):\n",
            "\n",
            "     Actual  Predicted\n",
            "256       0          0\n",
            "428       1          1\n",
            "501       0          0\n",
            "363       1          1\n",
            "564       0          0\n",
            "464       1          1\n",
            "358       1          1\n",
            "343       0          0\n",
            "516       0          0\n",
            "567       0          0\n",
            "292       1          1\n",
            "199       0          0\n",
            "527       1          1\n",
            "121       0          0\n",
            "353       0          0\n",
            "495       1          1\n",
            "541       1          0\n",
            "537       1          1\n",
            "308       1          1\n",
            "242       1          1\n",
            "Prediction: Benign (Non-Cancerous Tumor)\n",
            "Confidence: 0.9999945868088062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df= pd.read_csv(\"/content/sample_data/spam.csv\",encoding=\"latin-1\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "df=df[['v1','v2']]\n",
        "df.columns=['label','message']\n",
        "df.head()\n",
        "df['label']=df['label'].map({'ham':0,'spam':1})\n",
        "df.head()\n",
        "\n",
        "# Features (X) and target (y)\n",
        "X = df['message']\n",
        "y = df['label']\n",
        "print(X)\n",
        "print(y)\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "pip_log = Pipeline([\n",
        "    (\"vectorizer\",TfidfVectorizer(stop_words='english', max_features=5000)),\n",
        "    (\"clf\", LogisticRegression(max_iter=5000, random_state=42))\n",
        "])\n",
        "param_grid = {\n",
        "    \"clf__C\": [0.1, 1, 10],\n",
        "    \"clf__penalty\": [\"l2\"],\n",
        "    \"clf__solver\": [\"lbfgs\", \"saga\"]\n",
        "}\n",
        "grid_log= GridSearchCV(pip_log, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_log.fit(X_train, y_train)\n",
        "print(\"\\nBest Logistic Regression Params:\", grid_log.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_log.best_score_)\n",
        "y_pred_log = grid_log.predict(X_test)\n",
        "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "\n",
        "pip_svm = Pipeline([\n",
        "    (\"vectorizer\",TfidfVectorizer(stop_words='english', max_features=5000)),\n",
        "    (\"clf\",SVC(probability=True,random_state=42))\n",
        "])\n",
        "param_grid = {\n",
        "    \"clf__C\": [0.1, 1, 10],\n",
        "    \"clf__kernel\": [\"linear\",\"rbf\"],\n",
        "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
        "}\n",
        "grid_svm= GridSearchCV(pip_svm, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "print(\"\\nBest Logistic Regression Params:\", grid_svm.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_svm.best_score_)\n",
        "y_pred_svm = grid_svm.predict(X_test)\n",
        "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "\n",
        "\n",
        "pip_tree = Pipeline([\n",
        "    (\"vectorizer\",TfidfVectorizer(stop_words='english', max_features=5000)),\n",
        "    (\"clf\", RandomForestClassifier(random_state=42))\n",
        "])\n",
        "param_grid = {\n",
        "    \"clf__n_estimators\": [100,200],\n",
        "    \"clf__max_depth\": [10,20,None],\n",
        "    \"clf__min_samples_split\": [2,5]\n",
        "}\n",
        "grid_tree= GridSearchCV(pip_tree, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_tree.fit(X_train, y_train)\n",
        "print(\"\\nBest Logistic Regression Params:\", grid_tree.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_tree.best_score_)\n",
        "y_pred_tree = grid_tree.predict(X_test)\n",
        "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
        "\n",
        "results= {\n",
        "    \"Logistic Regression\": accuracy_score(y_test, y_pred_log),\n",
        "    \"SVM\": accuracy_score(y_test, y_pred_svm),\n",
        "    \"Random Forest\": accuracy_score(y_test, y_pred_tree)\n",
        "}\n",
        "print(\"\\nModel Comparison on Test Set:\")\n",
        "for model, accuracy_score in results.items():\n",
        "    print(f\"{model}: {accuracy_score: 4f}\")\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"\\nBest model is: {best_model}\")\n",
        "\n",
        "if best_model == \"Logistic Regression\":\n",
        "    final = grid_log.best_estimator_\n",
        "    y_best= y_pred_log\n",
        "elif best_model == \"SVM\":\n",
        "    final = grid_svm.best_estimator_\n",
        "    y_best= y_pred_svm\n",
        "else:\n",
        "    final = grid_tree.best_estimator_\n",
        "    y_best= y_pred_tree\n",
        "best_model= final.predict(X_test)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_best))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_best))\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(results.keys(), results.values(), color=[\"skyblue\",\"orange\",\"green\"])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Comparison on ham and spam\")\n",
        "plt.show()\n",
        "\n",
        "# ---------------- Predictive System ----------------\n",
        "def predict_message(message):\n",
        "    pred = final.predict([message])[0]\n",
        "    prob = final.predict_proba([message])[0]\n",
        "    label = \"ham\" if pred == 0 else \"spam\"\n",
        "    return label, prob\n",
        "\n",
        "# ---------------- Test Predictive System ----------------\n",
        "test_msg = \"Congratulations! You havenot won a $1000 Walmart gift card. Claim now!\"\n",
        "label, prob = predict_message(test_msg)\n",
        "print(\"\\nTest Message:\", test_msg)\n",
        "print(\"Prediction:\", label)\n",
        "print(\"Probabilities:\", prob)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vGxv1PmdxgdO",
        "outputId": "83fd65f1-0d6a-46e9-bd2b-34a1ea54bb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       Go until jurong point, crazy.. Available only ...\n",
            "1                           Ok lar... Joking wif u oni...\n",
            "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3       U dun say so early hor... U c already then say...\n",
            "4       Nah I don't think he goes to usf, he lives aro...\n",
            "                              ...                        \n",
            "5567    This is the 2nd time we have tried 2 contact u...\n",
            "5568                Will Ì_ b going to esplanade fr home?\n",
            "5569    Pity, * was in mood for that. So...any other s...\n",
            "5570    The guy did some bitching but I acted like i'd...\n",
            "5571                           Rofl. Its true to its name\n",
            "Name: message, Length: 5572, dtype: object\n",
            "0       0\n",
            "1       0\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "5567    1\n",
            "5568    0\n",
            "5569    0\n",
            "5570    0\n",
            "5571    0\n",
            "Name: label, Length: 5572, dtype: int64\n",
            "\n",
            "Best Logistic Regression Params: {'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'saga'}\n",
            "Best CV Accuracy: 0.9820507013332126\n",
            "Logistic Regression Test Accuracy: 0.9802690582959641\n",
            "\n",
            "Best Logistic Regression Params: {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
            "Best CV Accuracy: 0.9838456815287906\n",
            "Logistic Regression Test Accuracy: 0.9847533632286996\n",
            "\n",
            "Best Logistic Regression Params: {'clf__max_depth': None, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}\n",
            "Best CV Accuracy: 0.9824986285374925\n",
            "Logistic Regression Test Accuracy: 0.9766816143497757\n",
            "\n",
            "Model Comparison on Test Set:\n",
            "Logistic Regression:  0.980269\n",
            "SVM:  0.984753\n",
            "Random Forest:  0.976682\n",
            "\n",
            "Best model is: SVM\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       966\n",
            "           1       0.99      0.89      0.94       149\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.95      0.97      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[965   1]\n",
            " [ 16 133]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Message: Congratulations! You havenot won a $1000 Walmart gift card. Claim now!\n",
            "Prediction: spam\n",
            "Probabilities: [0.01365285 0.98634715]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/UCI_Heart_Disease_Dataset_Combined.csv')\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "X = df.drop(columns=['HeartDisease'])\n",
        "y = df['HeartDisease']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ---------------- Logistic Regression ----------------\n",
        "pipe_log = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=5000, random_state=42))\n",
        "])\n",
        "\n",
        "param_log = {\n",
        "    \"clf__C\": [0.1, 1, 10],\n",
        "    \"clf__solver\": [\"lbfgs\", \"liblinear\", \"saga\"]\n",
        "}\n",
        "\n",
        "grid_log = GridSearchCV(pipe_log, param_log, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_log.fit(X_train, y_train)\n",
        "y_pred_log = grid_log.predict(X_test)\n",
        "\n",
        "print(\"\\n🔹 Logistic Regression\")\n",
        "print(\"Best Params:\", grid_log.best_params_)\n",
        "print(\"CV Accuracy:\", grid_log.best_score_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "\n",
        "# ---------------- SVM ----------------\n",
        "pipe_svm = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", SVC(probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "param_svm = {\n",
        "    \"clf__C\": [0.1, 1, 10],\n",
        "    \"clf__kernel\": [\"linear\", \"rbf\"],\n",
        "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(pipe_svm, param_svm, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "y_pred_svm = grid_svm.predict(X_test)\n",
        "\n",
        "print(\"\\n🔹 Support Vector Machine\")\n",
        "print(\"Best Params:\", grid_svm.best_params_)\n",
        "print(\"CV Accuracy:\", grid_svm.best_score_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "\n",
        "# ---------------- Random Forest ----------------\n",
        "pipe_rf = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"clf\", RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_rf = {\n",
        "    \"clf__n_estimators\": [100, 200, 300],\n",
        "    \"clf__max_depth\": [10, 20, None],\n",
        "    \"clf__min_samples_split\": [2, 5, 10],\n",
        "    \"clf__min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(pipe_rf, param_rf, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "y_pred_rf = grid_rf.predict(X_test)\n",
        "\n",
        "print(\"\\n🔹 Random Forest\")\n",
        "print(\"Best Params:\", grid_rf.best_params_)\n",
        "print(\"CV Accuracy:\", grid_rf.best_score_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "\n",
        "# ---------------- Compare Models ----------------\n",
        "results = {\n",
        "    \"Logistic Regression\": accuracy_score(y_test, y_pred_log),\n",
        "    \"SVM\": accuracy_score(y_test, y_pred_svm),\n",
        "    \"Random Forest\": accuracy_score(y_test, y_pred_rf)\n",
        "}\n",
        "\n",
        "print(\"\\n Model Comparison on Test Set:\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.4f}\")\n",
        "\n",
        "best_model_name = max(results, key=results.get)\n",
        "print(f\"\\n Best Model is: {best_model_name}\")\n",
        "\n",
        "# ---------------- Final Predictive System ----------------\n",
        "if best_model_name == \"Logistic Regression\":\n",
        "    final_model = grid_log.best_estimator_\n",
        "elif best_model_name == \"SVM\":\n",
        "    final_model = grid_svm.best_estimator_\n",
        "else:\n",
        "    final_model = grid_rf.best_estimator_\n",
        "\n",
        "# ---------------- Manual Prediction Example ----------------\n",
        "\n",
        "sample_input = np.array([[40, 1, 1, 140, 289, 0, 0, 172, 0, 0]]).reshape(1,-1)\n",
        "\n",
        "sample_input = sample_input.reshape(1, -1)\n",
        "pred = final_model.predict(sample_input)\n",
        "\n",
        "if pred[0] == 0:\n",
        "    print(\"\\nPrediction:  No Heart Disease\")\n",
        "else:\n",
        "    print(\"\\nPrediction:  Heart Disease\")\n",
        "\n",
        "# ---------------- Reports ----------------\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, final_model.predict(X_test)))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, final_model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii-k_Mvkamzo",
        "outputId": "669e0186-3bf8-4c84-efa3-7716b26ae39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (2943, 11)\n",
            "Columns: ['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'HeartDisease']\n",
            "\n",
            "🔹 Logistic Regression\n",
            "Best Params: {'clf__C': 0.1, 'clf__solver': 'lbfgs'}\n",
            "CV Accuracy: 0.7383331074671364\n",
            "Test Accuracy: 0.7130730050933786\n",
            "\n",
            "🔹 Support Vector Machine\n",
            "Best Params: {'clf__C': 10, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n",
            "CV Accuracy: 0.8007634277454037\n",
            "Test Accuracy: 0.797962648556876\n",
            "\n",
            "🔹 Random Forest\n",
            "Best Params: {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\n",
            "CV Accuracy: 0.8755341735555857\n",
            "Test Accuracy: 0.9032258064516129\n",
            "\n",
            " Model Comparison on Test Set:\n",
            "Logistic Regression: 0.7131\n",
            "SVM: 0.7980\n",
            "Random Forest: 0.9032\n",
            "\n",
            " Best Model is: Random Forest\n",
            "\n",
            "Prediction:  No Heart Disease\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89       266\n",
            "           1       0.89      0.93      0.91       323\n",
            "\n",
            "    accuracy                           0.90       589\n",
            "   macro avg       0.90      0.90      0.90       589\n",
            "weighted avg       0.90      0.90      0.90       589\n",
            "\n",
            "Confusion Matrix:\n",
            " [[230  36]\n",
            " [ 21 302]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [`Doing a Project of predicting marks of math by Classification and Regression models`\n",
        " ]\n",
        "\n"
      ],
      "metadata": {
        "id": "BYpB40fDLKKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#--------------------LINEAR_MODEL--------------------------#\n",
        "\n",
        "df = pd.read_csv(\"/content/sample_data/StudentsPerformance.csv\")\n",
        "\n",
        "X = df.drop(columns=['math score','reading score','writing score'])\n",
        "y = df['math score']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "numeric_features = X.select_dtypes(include=['int64','float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('poly', PolynomialFeatures(include_bias=False)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'regressor': [LinearRegression()],\n",
        "        'preprocessor__num__poly__degree': [1, 2, 3]\n",
        "    },\n",
        "    {\n",
        "        'regressor': [RandomForestRegressor(random_state=42)],\n",
        "        'preprocessor__num__poly__degree': [1, 2],\n",
        "        'regressor__n_estimators': [100, 200],\n",
        "        'regressor__max_depth': [10, 20, None],\n",
        "        'regressor__min_samples_split': [2, 5]\n",
        "    }\n",
        "]\n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5, scoring=\"r2\", n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "pred = grid.predict(X_test)\n",
        "\n",
        "print(\"\\nBest Parameters:\", grid.best_params_)\n",
        "print(\" Best CV R²:\", grid.best_score_)\n",
        "print(\" Test MSE:\", mean_squared_error(y_test, pred))\n",
        "print(\"Test R²:\", r2_score(y_test, pred))\n",
        "print(\" Best Model Type:\", type(grid.best_estimator_.named_steps['regressor']).__name__)\n",
        "\n",
        "def manual_prediction():\n",
        "    gender= input(\"\\nenter gender: \")\n",
        "\n",
        "    race= input(\"\\nenter race: \")\n",
        "    parental_level_of_education= input(\"\\nenter parental level of education: \")\n",
        "    lunch= input(\"\\nenter lunch: \")\n",
        "    test_preparation_course= input(\"\\nenter test preparation course: \")\n",
        "    reading_score= float(input(\"\\nenter reading score: \"))\n",
        "    writing_score= float(input(\"\\nenter writing score: \"))\n",
        "    math= input(\"enter math score:\")\n",
        "\n",
        "    data= pd.DataFrame({\n",
        "        'gender': [gender],\n",
        "        'race/ethnicity': [race],\n",
        "        'parental level of education': [parental_level_of_education],\n",
        "        'lunch': [lunch],\n",
        "        'test preparation course': [test_preparation_course],\n",
        "        'reading score': [reading_score],\n",
        "        'writing score': [writing_score],\n",
        "        'math score': [math]\n",
        "    })\n",
        "    pred=grid.predict(data)[0]\n",
        "    print(pred)\n",
        "\n",
        "manual_prediction()\n",
        "ac = pd.DataFrame({\n",
        "    \"acyual\":y_test[:5],\n",
        "    \"predicted\":pred[:5]\n",
        "})\n",
        "print(ac)\n",
        "\n",
        "#\\n-------------------------Classification models---------------------------\\n\n",
        "\n",
        "df= pd.read_csv('/content/sample_data/StudentsPerformance.csv')\n",
        "df['math_cat']= pd.cut(df['math score'],bins=[0,60,80,100],labels=[\"low\",\"medium\",\"high\"])\n",
        "df = df.dropna(subset=['math_cat'])\n",
        "\n",
        "x= df.drop(columns=['math score','reading score','writing score'])\n",
        "y= df['math_cat']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "numeric_features = x.select_dtypes(include=['int64','float64']).columns\n",
        "categorical_features = x.select_dtypes(include=['object']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor= ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "pip= Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "param_grid = [{\n",
        "    'clf': [LogisticRegression(max_iter=1000)],\n",
        "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'clf__penalty': ['l2'],\n",
        "    'clf__solver': ['liblinear', 'saga']\n",
        "},\n",
        "{  'clf': [RandomForestClassifier(random_state=42)],\n",
        "    'clf__n_estimators': [100, 200, 300],\n",
        "    'clf__max_depth': [10, 20, None],\n",
        "    'clf__min_samples_split': [2,5]\n",
        "}]\n",
        "grid = GridSearchCV(pip, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"\\nBest Params:\", grid.best_params_)\n",
        "print(\"CV Accuracy:\", grid.best_score_)\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "y_test = y_test.astype(str)\n",
        "y_pred = y_pred.astype(str)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(type(grid.best_estimator_.named_steps['clf']).__name__)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "def manual_prediction():\n",
        "    gender= input(\"\\nenter gender: \")\n",
        "    race= input(\"\\nenter race: \")\n",
        "    parental_level_of_education= input(\"\\nenter parental level of education: \")\n",
        "    lunch= input(\"\\nenter lunch: \")\n",
        "    test_preparation_course= input(\"\\nenter test preparation course: \")\n",
        "    reading_score= float(input(\"\\nenter reading score: \"))\n",
        "    writing_score= float(input(\"\\nenter writing score: \"))\n",
        "\n",
        "\n",
        "    data = pd.DataFrame ({\n",
        "        'gender': [gender],\n",
        "        'race/ethnicity': [race],\n",
        "        'parental level of education': [parental_level_of_education],\n",
        "        'lunch': [lunch],\n",
        "        'test preparation course': [test_preparation_course],\n",
        "        'reading score': [reading_score],\n",
        "        'writing score': [writing_score]\n",
        "    })\n",
        "    pred=grid.predict(data)[0]\n",
        "    print(\"so math score: \",pred)\n",
        "\n",
        "manual_prediction()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_MaF0cQooKx",
        "outputId": "9f516018-1727-4b55-afed-50b6fadd9e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters: {'preprocessor__num__poly__degree': 1, 'regressor': LinearRegression()}\n",
            " Best CV R²: 0.23921977289505492\n",
            " Test MSE: 200.51088395807753\n",
            "Test R²: 0.17599982592933328\n",
            " Best Model Type: LinearRegression\n",
            "\n",
            "enter gender: FEMALE\n",
            "\n",
            "enter race: GROUP B\n",
            "\n",
            "enter parental level of education: bachelor's degree\n",
            "\n",
            "enter lunch: standard\n",
            "\n",
            "enter test preparation course: none\n",
            "\n",
            "enter reading score: 72\n",
            "\n",
            "enter writing score: 72\n",
            "enter math score:84\n",
            "72.81587077911337\n",
            "     acyual  predicted\n",
            "521      91  65.344269\n",
            "737      53  59.129273\n",
            "740      80  75.993294\n",
            "660      74  58.195987\n",
            "411      84  84.069558\n",
            "\n",
            "Best Params: {'clf': LogisticRegression(max_iter=1000), 'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'saga'}\n",
            "CV Accuracy: 0.5144025157232706\n",
            "Test Accuracy: 0.545\n",
            "LogisticRegression\n",
            "Confusion Matrix:\n",
            " [[ 3  1 29]\n",
            " [ 0 31 35]\n",
            " [ 5 21 75]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        high       0.38      0.09      0.15        33\n",
            "         low       0.58      0.47      0.52        66\n",
            "      medium       0.54      0.74      0.62       101\n",
            "\n",
            "    accuracy                           0.55       200\n",
            "   macro avg       0.50      0.43      0.43       200\n",
            "weighted avg       0.53      0.55      0.51       200\n",
            "\n",
            "\n",
            "enter gender: FEMALE\n",
            "\n",
            "enter race: GROUP B\n",
            "\n",
            "enter parental level of education: bachelor's degree\n",
            "\n",
            "enter lunch: standard\n",
            "\n",
            "enter test preparation course: none\n",
            "\n",
            "enter reading score: 72\n",
            "\n",
            "enter writing score: 74\n",
            "so math score:  medium\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/1okg4cdoTkb3jqtNUbA_oZ9wRE8BIe8WG/view?usp=drive_link"
      ],
      "metadata": {
        "id": "kjFXjZclFrLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicted loan_status by loan prediction dataset by classification models"
      ],
      "metadata": {
        "id": "3ZZcI-mCjz8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "df= pd.read_csv('/content/sample_data/train_u6lujuX_CVtuZ9i (1).csv')\n",
        "X= df.drop(columns=['Loan_ID','Loan_Status'])\n",
        "y= df['Loan_Status']\n",
        "\n",
        "numeric_features = X.select_dtypes(include=['int64','float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "col_trans= ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline= Pipeline([\n",
        "    ('preprocessor', col_trans),\n",
        "    ('clf', LogisticRegression(max_iter= 5000))\n",
        "])\n",
        "param_grid = [\n",
        "    {\n",
        "        'clf': [LogisticRegression(max_iter=5000)],\n",
        "        'clf__C': [0.1,0.01,0.001],\n",
        "        'clf__penalty': ['l2','l1'],\n",
        "        'clf__solver': ['liblinear','saga']\n",
        "    },\n",
        "    {\n",
        "        'clf': [SVC()],\n",
        "        'clf__C': [0.1, 1, 10],\n",
        "        'clf__kernel': ['linear', 'rbf'],\n",
        "        'clf__gamma': ['scale', 'auto']\n",
        "    },\n",
        "    {\n",
        "        'clf': [RandomForestClassifier(random_state=42)],\n",
        "        'clf__n_estimators': [100, 200, 300],\n",
        "        'clf__max_depth': [10, 20, None],\n",
        "    }\n",
        " ]\n",
        "\n",
        "grid= GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "y_pred= grid.predict(X_test)\n",
        "\n",
        "y_test = y_test.astype(str)\n",
        "y_pred = y_pred.astype(str)\n",
        "\n",
        "print(\"Best Model:\", type(grid.best_estimator_.named_steps['clf']).__name__)\n",
        "print(\"\\nBest Params:\", grid.best_params_)\n",
        "print(\"CV Accuracy:\", grid.best_score_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "def manual_prediction():\n",
        "    gender= input(\"\\nenter gender: \")\n",
        "    married= input(\"\\nenter married: \")\n",
        "    dependents= input(\"\\nenter dependents: \")\n",
        "    education= input(\"\\nenter education: \")\n",
        "    self_employed= input(\"\\nenter self employed: \")\n",
        "    applicant_income= float(input(\"\\nenter applicant income: \"))\n",
        "    coapplicant_income= float(input(\"\\nenter coapplicant income: \"))\n",
        "    loan_amount= float(input(\"\\nenter loan amount: \"))\n",
        "    loan_amount_term= float(input(\"\\nenter loan amount term: \"))\n",
        "    credit_history= float(input(\"\\nenter credit history: \"))\n",
        "    property_area= input(\"\\nenter property area: \")\n",
        "\n",
        "    data = pd.DataFrame ({\n",
        "        'Gender': [gender],\n",
        "        'Married': [married],\n",
        "        'Dependents': [dependents],\n",
        "        'Education': [education],\n",
        "        'Self_Employed': [self_employed],\n",
        "        'ApplicantIncome': [applicant_income],\n",
        "        'CoapplicantIncome': [coapplicant_income],\n",
        "        'LoanAmount': [loan_amount],\n",
        "        'Loan_Amount_Term': [loan_amount_term],\n",
        "        'Credit_History': [credit_history],\n",
        "         'Property_Area': [property_area]\n",
        "    })\n",
        "    pred= grid.predict(data)[0]\n",
        "    print(\"is there any loan status?\", pred)\n",
        "    if pred == 'Y':\n",
        "        print(\"yes\")\n",
        "    else:\n",
        "        print(\"no\")\n",
        "manual_prediction()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8qAXr47ORi0",
        "outputId": "b82a7ab2-1557-461e-b5e3-018f13948e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: LogisticRegression\n",
            "\n",
            "Best Params: {'clf': LogisticRegression(max_iter=5000), 'clf__C': 0.1, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
            "CV Accuracy: 0.8145949288806431\n",
            "Test Accuracy: 0.7886178861788617\n",
            "\n",
            "enter gender: male\n",
            "\n",
            "enter married: no\n",
            "\n",
            "enter dependents: 0\n",
            "\n",
            "enter education: Graduate\n",
            "\n",
            "enter self employed: no\n",
            "\n",
            "enter applicant income: 5849\n",
            "\n",
            "enter coapplicant income: 0\n",
            "\n",
            "enter loan amount: 0\n",
            "\n",
            "enter loan amount term: 360\n",
            "\n",
            "enter credit history: 1\n",
            "\n",
            "enter property area: Urban\n",
            "is there any loan status? Y\n",
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "df= pd.read_csv('/content/sample_data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "x= df.drop(columns=['customerID','Churn'])\n",
        "y= df['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "numeric_features = x.select_dtypes(include=['int64','float64']).columns\n",
        "categorical_features = x.select_dtypes(include=['object']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "col_trans= ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "model= Pipeline([\n",
        "    ('preprocessor', col_trans),\n",
        "    ('clf', LogisticRegression(max_iter= 5000))\n",
        "])\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'clf': [LogisticRegression(max_iter=5000)],\n",
        "        'clf__C': [0.1,0.01,0.001],\n",
        "        'clf__penalty': ['l2','l1'],\n",
        "        'clf__solver': ['liblinear','saga']\n",
        "    },\n",
        "    {\n",
        "        'clf': [SVC()],\n",
        "        'clf__C': [0.1, 1, 10],\n",
        "        'clf__kernel': ['linear', 'rbf'],\n",
        "        'clf__gamma': ['scale', 'auto']\n",
        "    },\n",
        "    {\n",
        "        'clf': [RandomForestClassifier(random_state=42)],\n",
        "        'clf__n_estimators': [100, 200, 300],\n",
        "        'clf__max_depth': [10, 20, None],\n",
        "        'clf__min_samples_split': [2,5]\n",
        "    }\n",
        "\n",
        "]\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "y_test = y_test.astype(str)\n",
        "y_pred = y_pred.astype(str)\n",
        "print(\"accuracy acore: \",accuracy_score(y_test,y_pred))\n",
        "print(\"Best Model:\", type(grid.best_estimator_.named_steps['clf']).__name__)\n",
        "print(\"\\nBest Params:\", grid.best_params_)\n",
        "print(\"CV Accuracy:\", grid.best_score_)\n",
        "print(\"confusion matrix: \", confusion_matrix(y_test, y_pred))\n",
        "print(\"classification report: \", classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aZfTSD23Wn8",
        "outputId": "e81923f6-72fe-42fc-a65e-9bfa0206faa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy acore:  0.8246983676366217\n",
            "Best Model: LogisticRegression\n",
            "\n",
            "Best Params: {'clf': LogisticRegression(max_iter=5000), 'clf__C': 0.1, 'clf__penalty': 'l1', 'clf__solver': 'saga'}\n",
            "CV Accuracy: 0.8017397923722737\n",
            "confusion matrix:  [[944  92]\n",
            " [155 218]]\n",
            "classification report:                precision    recall  f1-score   support\n",
            "\n",
            "          No       0.86      0.91      0.88      1036\n",
            "         Yes       0.70      0.58      0.64       373\n",
            "\n",
            "    accuracy                           0.82      1409\n",
            "   macro avg       0.78      0.75      0.76      1409\n",
            "weighted avg       0.82      0.82      0.82      1409\n",
            "\n"
          ]
        }
      ]
    }
  ]
}